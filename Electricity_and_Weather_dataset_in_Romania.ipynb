{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 8013164,
          "datasetId": 3021996,
          "databundleVersionId": 8125193
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 3373208,
          "datasetId": 2030471,
          "databundleVersionId": 3424612
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Electricity and Weather dataset in Romania",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajayrajc1998/multivariate_LSTM/blob/main/Electricity_and_Weather_dataset_in_Romania.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "acatalin14_romania_weather_visual_crossing_weather_path = kagglehub.dataset_download('acatalin14/romania-weather-visual-crossing-weather')\n",
        "stefancomanita_hourly_electricity_consumption_and_production_path = kagglehub.dataset_download('stefancomanita/hourly-electricity-consumption-and-production')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "HoFopfLXlHzQ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nVIhE29hlHzU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"stefancomanita/hourly-electricity-consumption-and-production\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T14:53:30.821029Z",
          "iopub.execute_input": "2024-11-26T14:53:30.82151Z",
          "iopub.status.idle": "2024-11-26T14:53:35.765708Z",
          "shell.execute_reply.started": "2024-11-26T14:53:30.821472Z",
          "shell.execute_reply": "2024-11-26T14:53:35.764412Z"
        },
        "id": "yLhwCBBilHzV",
        "outputId": "c635a948-84ee-49d1-c0b0-df239255cfb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Path to dataset files: /kaggle/input/hourly-electricity-consumption-and-production\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"acatalin14/romania-weather-visual-crossing-weather\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T14:55:30.254388Z",
          "iopub.execute_input": "2024-11-26T14:55:30.255529Z",
          "iopub.status.idle": "2024-11-26T14:55:39.121533Z",
          "shell.execute_reply.started": "2024-11-26T14:55:30.255487Z",
          "shell.execute_reply": "2024-11-26T14:55:39.120399Z"
        },
        "id": "SX2oqYJVlHzX",
        "outputId": "30a95b13-890d-4244-fafc-d7e21d30f780"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Path to dataset files: /kaggle/input/romania-weather-visual-crossing-weather\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv('/kaggle/input/hourly-electricity-consumption-and-production/electricityConsumptionAndProductioction.csv')\n",
        "df2=pd.read_csv('/kaggle/input/romania-weather-visual-crossing-weather/weather_2011-2021_Romania.csv', encoding='latin1')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:09:16.881385Z",
          "iopub.execute_input": "2024-11-26T15:09:16.881793Z",
          "iopub.status.idle": "2024-11-26T15:09:17.777083Z",
          "shell.execute_reply.started": "2024-11-26T15:09:16.881758Z",
          "shell.execute_reply": "2024-11-26T15:09:17.775808Z"
        },
        "id": "JASj4cQnlHzY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:10:16.743662Z",
          "iopub.execute_input": "2024-11-26T15:10:16.744068Z",
          "iopub.status.idle": "2024-11-26T15:10:16.759222Z",
          "shell.execute_reply.started": "2024-11-26T15:10:16.744035Z",
          "shell.execute_reply": "2024-11-26T15:10:16.757911Z"
        },
        "id": "s3UNkKhmlHzY",
        "outputId": "ec722c0e-11c1-4422-ee73-4708f3cf39dd"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              DateTime  Consumption  Production  Nuclear  Wind  Hydroelectric  \\\n0  2019-01-01 00:00:00         6352        6527     1395    79           1383   \n1  2019-01-01 01:00:00         6116        5701     1393    96           1112   \n2  2019-01-01 02:00:00         5873        5676     1393   142           1030   \n3  2019-01-01 03:00:00         5682        5603     1397   191            972   \n4  2019-01-01 04:00:00         5557        5454     1393   159            960   \n\n   Oil and Gas  Coal  Solar  Biomass  \n0         1896  1744      0       30  \n1         1429  1641      0       30  \n2         1465  1616      0       30  \n3         1455  1558      0       30  \n4         1454  1458      0       30  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>Consumption</th>\n      <th>Production</th>\n      <th>Nuclear</th>\n      <th>Wind</th>\n      <th>Hydroelectric</th>\n      <th>Oil and Gas</th>\n      <th>Coal</th>\n      <th>Solar</th>\n      <th>Biomass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01 00:00:00</td>\n      <td>6352</td>\n      <td>6527</td>\n      <td>1395</td>\n      <td>79</td>\n      <td>1383</td>\n      <td>1896</td>\n      <td>1744</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-01 01:00:00</td>\n      <td>6116</td>\n      <td>5701</td>\n      <td>1393</td>\n      <td>96</td>\n      <td>1112</td>\n      <td>1429</td>\n      <td>1641</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-01 02:00:00</td>\n      <td>5873</td>\n      <td>5676</td>\n      <td>1393</td>\n      <td>142</td>\n      <td>1030</td>\n      <td>1465</td>\n      <td>1616</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-01 03:00:00</td>\n      <td>5682</td>\n      <td>5603</td>\n      <td>1397</td>\n      <td>191</td>\n      <td>972</td>\n      <td>1455</td>\n      <td>1558</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-01 04:00:00</td>\n      <td>5557</td>\n      <td>5454</td>\n      <td>1393</td>\n      <td>159</td>\n      <td>960</td>\n      <td>1454</td>\n      <td>1458</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:18:22.681279Z",
          "iopub.execute_input": "2024-11-26T15:18:22.681659Z",
          "iopub.status.idle": "2024-11-26T15:18:22.708692Z",
          "shell.execute_reply.started": "2024-11-26T15:18:22.681629Z",
          "shell.execute_reply": "2024-11-26T15:18:22.707525Z"
        },
        "id": "eHh24qlWlHzY",
        "outputId": "bf4dbac9-1902-4e9d-9f71-3e576cd16990"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "               Address   Date time  Minimum Temperature  Maximum Temperature  \\\n0  Alba Iulia, Romania  01/01/2011                -10.1                 -3.6   \n1  Alba Iulia, Romania  01/02/2011                 -9.0                 -1.7   \n2  Alba Iulia, Romania  01/03/2011                 -7.2                 -1.8   \n3  Alba Iulia, Romania  01/04/2011                 -6.7                 -4.5   \n4  Alba Iulia, Romania  01/05/2011                -11.5                 -5.0   \n\n   Temperature  Dew Point  Relative Humidity  Heat Index  Wind Speed  \\\n0         -6.9       -8.2              90.62         NaN         8.9   \n1         -4.6       -6.0              89.80         NaN         8.8   \n2         -4.0       -5.0              93.01         NaN         8.7   \n3         -5.7       -7.4              87.73         NaN         7.0   \n4         -7.9      -10.2              83.54         NaN         8.0   \n\n   Wind Gust  ...  Visibility  Cloud Cover  Sea Level Pressure  \\\n0       21.6  ...         4.8         71.6              1022.3   \n1       14.4  ...         6.5         74.1              1017.9   \n2        7.2  ...         4.3         94.5              1021.1   \n3       14.4  ...         7.4         96.6              1026.5   \n4       15.1  ...         8.1         61.1              1027.9   \n\n                                      Weather Type  Latitude  Longitude  \\\n0                                             Mist   46.0709    23.5805   \n1                            Mist, Light Snow, Fog   46.0709    23.5805   \n2                      Mist, Light Snow, Fog, Snow   46.0709    23.5805   \n3  Mist, Light Snow, Sky Coverage Increasing, Snow   46.0709    23.5805   \n4                                             Mist   46.0709    23.5805   \n\n      Resolved Address                 Name Info        Conditions  \n0  Alba Iulia, România  Alba Iulia, România  NaN  Partially cloudy  \n1  Alba Iulia, România  Alba Iulia, România  NaN  Partially cloudy  \n2  Alba Iulia, România  Alba Iulia, România  NaN          Overcast  \n3  Alba Iulia, România  Alba Iulia, România  NaN          Overcast  \n4  Alba Iulia, România  Alba Iulia, România  NaN  Partially cloudy  \n\n[5 rows x 25 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Address</th>\n      <th>Date time</th>\n      <th>Minimum Temperature</th>\n      <th>Maximum Temperature</th>\n      <th>Temperature</th>\n      <th>Dew Point</th>\n      <th>Relative Humidity</th>\n      <th>Heat Index</th>\n      <th>Wind Speed</th>\n      <th>Wind Gust</th>\n      <th>...</th>\n      <th>Visibility</th>\n      <th>Cloud Cover</th>\n      <th>Sea Level Pressure</th>\n      <th>Weather Type</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Resolved Address</th>\n      <th>Name</th>\n      <th>Info</th>\n      <th>Conditions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alba Iulia, Romania</td>\n      <td>01/01/2011</td>\n      <td>-10.1</td>\n      <td>-3.6</td>\n      <td>-6.9</td>\n      <td>-8.2</td>\n      <td>90.62</td>\n      <td>NaN</td>\n      <td>8.9</td>\n      <td>21.6</td>\n      <td>...</td>\n      <td>4.8</td>\n      <td>71.6</td>\n      <td>1022.3</td>\n      <td>Mist</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alba Iulia, Romania</td>\n      <td>01/02/2011</td>\n      <td>-9.0</td>\n      <td>-1.7</td>\n      <td>-4.6</td>\n      <td>-6.0</td>\n      <td>89.80</td>\n      <td>NaN</td>\n      <td>8.8</td>\n      <td>14.4</td>\n      <td>...</td>\n      <td>6.5</td>\n      <td>74.1</td>\n      <td>1017.9</td>\n      <td>Mist, Light Snow, Fog</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alba Iulia, Romania</td>\n      <td>01/03/2011</td>\n      <td>-7.2</td>\n      <td>-1.8</td>\n      <td>-4.0</td>\n      <td>-5.0</td>\n      <td>93.01</td>\n      <td>NaN</td>\n      <td>8.7</td>\n      <td>7.2</td>\n      <td>...</td>\n      <td>4.3</td>\n      <td>94.5</td>\n      <td>1021.1</td>\n      <td>Mist, Light Snow, Fog, Snow</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Overcast</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alba Iulia, Romania</td>\n      <td>01/04/2011</td>\n      <td>-6.7</td>\n      <td>-4.5</td>\n      <td>-5.7</td>\n      <td>-7.4</td>\n      <td>87.73</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>14.4</td>\n      <td>...</td>\n      <td>7.4</td>\n      <td>96.6</td>\n      <td>1026.5</td>\n      <td>Mist, Light Snow, Sky Coverage Increasing, Snow</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Overcast</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alba Iulia, Romania</td>\n      <td>01/05/2011</td>\n      <td>-11.5</td>\n      <td>-5.0</td>\n      <td>-7.9</td>\n      <td>-10.2</td>\n      <td>83.54</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>15.1</td>\n      <td>...</td>\n      <td>8.1</td>\n      <td>61.1</td>\n      <td>1027.9</td>\n      <td>Mist</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Partially cloudy</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:39:01.20725Z",
          "iopub.execute_input": "2024-11-26T15:39:01.207703Z",
          "iopub.status.idle": "2024-11-26T15:39:01.289153Z",
          "shell.execute_reply.started": "2024-11-26T15:39:01.207665Z",
          "shell.execute_reply": "2024-11-26T15:39:01.287916Z"
        },
        "id": "DFuBnwXrlHzZ",
        "outputId": "826c8cb9-7946-4a67-a6b8-caa1890e0a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 164738 entries, 2011-01-01 to 2021-12-31\nData columns (total 24 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   Address              164738 non-null  object \n 1   Minimum Temperature  164732 non-null  float64\n 2   Maximum Temperature  164732 non-null  float64\n 3   Temperature          164732 non-null  float64\n 4   Dew Point            164731 non-null  float64\n 5   Relative Humidity    164731 non-null  float64\n 6   Heat Index           34034 non-null   float64\n 7   Wind Speed           164727 non-null  float64\n 8   Wind Gust            137077 non-null  float64\n 9   Wind Direction       164729 non-null  float64\n 10  Wind Chill           96851 non-null   float64\n 11  Precipitation        164738 non-null  float64\n 12  Precipitation Cover  164732 non-null  float64\n 13  Snow Depth           103204 non-null  float64\n 14  Visibility           164731 non-null  float64\n 15  Cloud Cover          164732 non-null  float64\n 16  Sea Level Pressure   150369 non-null  float64\n 17  Weather Type         133762 non-null  object \n 18  Latitude             164738 non-null  float64\n 19  Longitude            164738 non-null  float64\n 20  Resolved Address     164738 non-null  object \n 21  Name                 164738 non-null  object \n 22  Info                 0 non-null       float64\n 23  Conditions           164732 non-null  object \ndtypes: float64(19), object(5)\nmemory usage: 35.5+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df2.columns:\n",
        "    if df2[i].dtype=='float64':\n",
        "        print(f'range of the feature {i}')\n",
        "        print('(range: ',df2[i].min(),'-',df2[i].max(),')')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T16:31:02.315006Z",
          "iopub.execute_input": "2024-11-26T16:31:02.315437Z",
          "iopub.status.idle": "2024-11-26T16:31:02.35357Z",
          "shell.execute_reply.started": "2024-11-26T16:31:02.315398Z",
          "shell.execute_reply": "2024-11-26T16:31:02.352381Z"
        },
        "id": "6FQRDOiFlHza",
        "outputId": "bfeb710a-7528-4d6d-8bae-be6197aac842"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "range of the feature Minimum Temperature\n(range:  -29.1 - 27.3 )\nrange of the feature Maximum Temperature\n(range:  -21.5 - 42.1 )\nrange of the feature Temperature\n(range:  -23.7 - 32.4 )\nrange of the feature Dew Point\n(range:  -42.8 - 23.7 )\nrange of the feature Relative Humidity\n(range:  3.05 - 100.0 )\nrange of the feature Heat Index\n(range:  25.8 - 88.0 )\nrange of the feature Wind Speed\n(range:  0.0 - 187.1 )\nrange of the feature Wind Gust\n(range:  0.0 - 230.4 )\nrange of the feature Wind Direction\n(range:  7.71 - 360.0 )\nrange of the feature Wind Chill\n(range:  -44.7 - 9.8 )\nrange of the feature Precipitation\n(range:  0.0 - 308.0 )\nrange of the feature Precipitation Cover\n(range:  0.0 - 100.0 )\nrange of the feature Snow Depth\n(range:  0.0 - 998.0 )\nrange of the feature Visibility\n(range:  0.0 - 222.9 )\nrange of the feature Cloud Cover\n(range:  0.0 - 100.0 )\nrange of the feature Sea Level Pressure\n(range:  939.4 - 1060.6 )\nrange of the feature Latitude\n(range:  43.9147 - 47.7933 )\nrange of the feature Longitude\n(range:  21.2233 - 28.80233 )\nrange of the feature Info\n(range:  nan - nan )\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Conditions'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T16:35:27.613724Z",
          "iopub.execute_input": "2024-11-26T16:35:27.614134Z",
          "iopub.status.idle": "2024-11-26T16:35:27.63036Z",
          "shell.execute_reply.started": "2024-11-26T16:35:27.614087Z",
          "shell.execute_reply": "2024-11-26T16:35:27.629234Z"
        },
        "id": "HWv0IihclHza",
        "outputId": "f205b1a3-f3c8-4199-d0ab-13c67fb7735c"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Partially cloudy', 'Overcast', 'Clear', 'Rain, Overcast',\n       'Rain, Partially cloudy', 'Rain', nan], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Name'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T16:37:25.103366Z",
          "iopub.execute_input": "2024-11-26T16:37:25.103771Z",
          "iopub.status.idle": "2024-11-26T16:37:25.122622Z",
          "shell.execute_reply.started": "2024-11-26T16:37:25.103736Z",
          "shell.execute_reply": "2024-11-26T16:37:25.121509Z"
        },
        "id": "5tvu44ldlHza",
        "outputId": "e5245940-2835-4101-d187-f141eb72a7a2"
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Alba Iulia, România', 'Arad, România', 'Pite<U+0219>ti, România',\n       'Bacau, România', 'Oradea, România', 'Bistri<U+021B>a, România',\n       'Boto<U+0219>ani, România', 'Braila, România',\n       'Bra<U+0219>ov, România', 'Bucure<U+0219>ti, România',\n       'Buzau, România', 'Calara<U+0219>i, România',\n       'Re<U+0219>i<U+021B>a, România', 'Cluj-Napoca, România',\n       'Constan<U+021B>a, România', 'Sfântu Gheorghe, România',\n       'Târgovi<U+0219>te, România', 'Craiova, România',\n       'Gala<U+021B>i, România', 'Giurgiu, România', 'Târgu Jiu, România',\n       'Miercurea Ciuc, România', 'Deva, România', 'Slobozia, România',\n       'Ia<U+0219>i, România', 'Baia Mare, România',\n       'Drobeta-Turnu Severin, România', 'Târgu Mure<U+0219>, România',\n       'Piatra Neam<U+021B>, România', 'Slatina, România',\n       'Ploie<U+0219>ti, România', 'Zalau, România', 'Satu Mare, România',\n       'Sibiu, România', 'Suceava, România', 'Alexandria, România',\n       'Timi<U+0219>oara, România', 'Tulcea, România',\n       'Râmnicu Vâlcea, România', 'Vaslui, România',\n       'Foc<U+0219>ani, România', 'Bihor, România'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def date_set_index(df,date_col):\n",
        "    df[date_col]=pd.to_datetime(df[date_col])\n",
        "    df.index=df[date_col]\n",
        "    df.drop(date_col,axis=1,inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:12:21.981442Z",
          "iopub.execute_input": "2024-11-26T15:12:21.982624Z",
          "iopub.status.idle": "2024-11-26T15:12:21.988268Z",
          "shell.execute_reply.started": "2024-11-26T15:12:21.982574Z",
          "shell.execute_reply": "2024-11-26T15:12:21.987077Z"
        },
        "id": "ag8RZ5uilHza"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1=date_set_index(df1,'DateTime')\n",
        "df1_resampled = df1.resample('D').mean()  # or other aggregation method\n",
        "# df2_resampled = df2.resample('D').mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:18:06.522913Z",
          "iopub.execute_input": "2024-11-26T15:18:06.523373Z",
          "iopub.status.idle": "2024-11-26T15:18:06.578781Z",
          "shell.execute_reply.started": "2024-11-26T15:18:06.523336Z",
          "shell.execute_reply": "2024-11-26T15:18:06.577613Z"
        },
        "id": "Z29AWxNTlHzb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2=date_set_index(df2,'Date time')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:18:58.891745Z",
          "iopub.execute_input": "2024-11-26T15:18:58.892128Z",
          "iopub.status.idle": "2024-11-26T15:18:59.314226Z",
          "shell.execute_reply.started": "2024-11-26T15:18:58.892095Z",
          "shell.execute_reply": "2024-11-26T15:18:59.312862Z"
        },
        "id": "javzoYA9lHzb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-26T15:19:58.866134Z",
          "iopub.execute_input": "2024-11-26T15:19:58.86659Z",
          "iopub.status.idle": "2024-11-26T15:19:58.897286Z",
          "shell.execute_reply.started": "2024-11-26T15:19:58.866555Z",
          "shell.execute_reply": "2024-11-26T15:19:58.896143Z"
        },
        "id": "zyx1JoJKlHzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "def merge_data(df1,df2):\n",
        "    merged_df=pd.merge(df1,df2,left_index=True,right_index=True)\n",
        "    merged_df.fillna(method='ffill',inplace=True)\n",
        "    return merged_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:23:07.679137Z",
          "iopub.execute_input": "2024-11-26T15:23:07.679625Z",
          "iopub.status.idle": "2024-11-26T15:23:08.122811Z",
          "shell.execute_reply.started": "2024-11-26T15:23:07.679582Z",
          "shell.execute_reply": "2024-11-26T15:23:08.121696Z"
        },
        "id": "XPYaIUD9lHzc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df=merge_data(df1_resampled,df2)\n",
        "merged_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T15:23:40.285661Z",
          "iopub.execute_input": "2024-11-26T15:23:40.286337Z",
          "iopub.status.idle": "2024-11-26T15:23:40.374836Z",
          "shell.execute_reply.started": "2024-11-26T15:23:40.286267Z",
          "shell.execute_reply": "2024-11-26T15:23:40.373639Z"
        },
        "id": "vd9Vz6sTlHzc",
        "outputId": "5299fb23-42cb-4d30-df4b-7fe1981aeeb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_30/2194172848.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  merged_df.fillna(method='ffill',inplace=True)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Consumption   Production  Nuclear        Wind  Hydroelectric  \\\nDateTime                                                                   \n2019-01-01  5957.666667  5924.416667  1391.75  343.583333       1285.875   \n2019-01-01  5957.666667  5924.416667  1391.75  343.583333       1285.875   \n2019-01-01  5957.666667  5924.416667  1391.75  343.583333       1285.875   \n2019-01-01  5957.666667  5924.416667  1391.75  343.583333       1285.875   \n2019-01-01  5957.666667  5924.416667  1391.75  343.583333       1285.875   \n\n            Oil and Gas         Coal      Solar    Biomass  \\\nDateTime                                                     \n2019-01-01       1418.0  1408.708333  43.291667  32.791667   \n2019-01-01       1418.0  1408.708333  43.291667  32.791667   \n2019-01-01       1418.0  1408.708333  43.291667  32.791667   \n2019-01-01       1418.0  1408.708333  43.291667  32.791667   \n2019-01-01       1418.0  1408.708333  43.291667  32.791667   \n\n                        Address  ...  Visibility  Cloud Cover  \\\nDateTime                         ...                            \n2019-01-01  Alba Iulia, Romania  ...         8.3         64.4   \n2019-01-01        Arad, Romania  ...         4.9         49.7   \n2019-01-01     Pitesti, Romania  ...         3.3         39.6   \n2019-01-01       Bacau, Romania  ...         6.4         39.6   \n2019-01-01      Oradea, Romania  ...         7.5         63.7   \n\n            Sea Level Pressure  \\\nDateTime                         \n2019-01-01              1026.5   \n2019-01-01              1027.2   \n2019-01-01              1025.8   \n2019-01-01              1024.1   \n2019-01-01              1026.4   \n\n                                                 Weather Type  Latitude  \\\nDateTime                                                                  \n2019-01-01                                          Mist, Fog   46.0709   \n2019-01-01  Mist, Heavy Rain And Snow, Light Rain And Snow...   46.1807   \n2019-01-01                                          Mist, Fog   44.8515   \n2019-01-01                                          Mist, Fog   46.5691   \n2019-01-01  Mist, Light Snow, Heavy Rain And Snow, Fog, Li...   47.0518   \n\n            Longitude         Resolved Address                     Name  Info  \\\nDateTime                                                                        \n2019-01-01    23.5805      Alba Iulia, România      Alba Iulia, România   NaN   \n2019-01-01    21.3221            Arad, România            Arad, România   NaN   \n2019-01-01    24.8799  Pite<U+0219>ti, România  Pite<U+0219>ti, România   NaN   \n2019-01-01    26.9110           Bacau, România           Bacau, România   NaN   \n2019-01-01    21.9387          Oradea, România          Oradea, România   NaN   \n\n                        Conditions  \nDateTime                            \n2019-01-01        Partially cloudy  \n2019-01-01  Rain, Partially cloudy  \n2019-01-01        Partially cloudy  \n2019-01-01  Rain, Partially cloudy  \n2019-01-01  Rain, Partially cloudy  \n\n[5 rows x 33 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Consumption</th>\n      <th>Production</th>\n      <th>Nuclear</th>\n      <th>Wind</th>\n      <th>Hydroelectric</th>\n      <th>Oil and Gas</th>\n      <th>Coal</th>\n      <th>Solar</th>\n      <th>Biomass</th>\n      <th>Address</th>\n      <th>...</th>\n      <th>Visibility</th>\n      <th>Cloud Cover</th>\n      <th>Sea Level Pressure</th>\n      <th>Weather Type</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Resolved Address</th>\n      <th>Name</th>\n      <th>Info</th>\n      <th>Conditions</th>\n    </tr>\n    <tr>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01</th>\n      <td>5957.666667</td>\n      <td>5924.416667</td>\n      <td>1391.75</td>\n      <td>343.583333</td>\n      <td>1285.875</td>\n      <td>1418.0</td>\n      <td>1408.708333</td>\n      <td>43.291667</td>\n      <td>32.791667</td>\n      <td>Alba Iulia, Romania</td>\n      <td>...</td>\n      <td>8.3</td>\n      <td>64.4</td>\n      <td>1026.5</td>\n      <td>Mist, Fog</td>\n      <td>46.0709</td>\n      <td>23.5805</td>\n      <td>Alba Iulia, România</td>\n      <td>Alba Iulia, România</td>\n      <td>NaN</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>5957.666667</td>\n      <td>5924.416667</td>\n      <td>1391.75</td>\n      <td>343.583333</td>\n      <td>1285.875</td>\n      <td>1418.0</td>\n      <td>1408.708333</td>\n      <td>43.291667</td>\n      <td>32.791667</td>\n      <td>Arad, Romania</td>\n      <td>...</td>\n      <td>4.9</td>\n      <td>49.7</td>\n      <td>1027.2</td>\n      <td>Mist, Heavy Rain And Snow, Light Rain And Snow...</td>\n      <td>46.1807</td>\n      <td>21.3221</td>\n      <td>Arad, România</td>\n      <td>Arad, România</td>\n      <td>NaN</td>\n      <td>Rain, Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>5957.666667</td>\n      <td>5924.416667</td>\n      <td>1391.75</td>\n      <td>343.583333</td>\n      <td>1285.875</td>\n      <td>1418.0</td>\n      <td>1408.708333</td>\n      <td>43.291667</td>\n      <td>32.791667</td>\n      <td>Pitesti, Romania</td>\n      <td>...</td>\n      <td>3.3</td>\n      <td>39.6</td>\n      <td>1025.8</td>\n      <td>Mist, Fog</td>\n      <td>44.8515</td>\n      <td>24.8799</td>\n      <td>Pite&lt;U+0219&gt;ti, România</td>\n      <td>Pite&lt;U+0219&gt;ti, România</td>\n      <td>NaN</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>5957.666667</td>\n      <td>5924.416667</td>\n      <td>1391.75</td>\n      <td>343.583333</td>\n      <td>1285.875</td>\n      <td>1418.0</td>\n      <td>1408.708333</td>\n      <td>43.291667</td>\n      <td>32.791667</td>\n      <td>Bacau, Romania</td>\n      <td>...</td>\n      <td>6.4</td>\n      <td>39.6</td>\n      <td>1024.1</td>\n      <td>Mist, Fog</td>\n      <td>46.5691</td>\n      <td>26.9110</td>\n      <td>Bacau, România</td>\n      <td>Bacau, România</td>\n      <td>NaN</td>\n      <td>Rain, Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>5957.666667</td>\n      <td>5924.416667</td>\n      <td>1391.75</td>\n      <td>343.583333</td>\n      <td>1285.875</td>\n      <td>1418.0</td>\n      <td>1408.708333</td>\n      <td>43.291667</td>\n      <td>32.791667</td>\n      <td>Oradea, Romania</td>\n      <td>...</td>\n      <td>7.5</td>\n      <td>63.7</td>\n      <td>1026.4</td>\n      <td>Mist, Light Snow, Heavy Rain And Snow, Fog, Li...</td>\n      <td>47.0518</td>\n      <td>21.9387</td>\n      <td>Oradea, România</td>\n      <td>Oradea, România</td>\n      <td>NaN</td>\n      <td>Rain, Partially cloudy</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "sCn2HBCXlHzc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tesing the code given for cleaning the data for LSTM prediction of the target column 'Consumption' in electricity data"
      ],
      "metadata": {
        "id": "HSzPwlXglHzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load datasets\n",
        "electricity_data=pd.read_csv('/kaggle/input/hourly-electricity-consumption-and-production/electricityConsumptionAndProductioction.csv')\n",
        "weather_data=pd.read_csv('/kaggle/input/romania-weather-visual-crossing-weather/weather_2011-2021_Romania.csv', encoding='latin1')\n",
        "\n",
        "# Convert datetime columns to pandas datetime format\n",
        "electricity_data['DateTime'] = pd.to_datetime(electricity_data['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
        "weather_data['DateTime'] = pd.to_datetime(weather_data['Date time'], format='%m/%d/%Y')\n",
        "\n",
        "# Set DateTime as the index for both datasets\n",
        "electricity_data.set_index('DateTime', inplace=True)\n",
        "weather_data.set_index('DateTime', inplace=True)\n",
        "\n",
        "# Drop unnecessary columns from the weather dataset\n",
        "weather_data.drop(['Address', 'Name', 'Info', 'Resolved Address', 'Latitude', 'Longitude'], axis=1, inplace=True)\n",
        "\n",
        "# Resample weather data to hourly frequency using forward fill\n",
        "weather_data = weather_data.resample('H').ffill()\n",
        "\n",
        "# Merge datasets on DateTime\n",
        "merged_data = pd.merge(electricity_data, weather_data, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "# 1. Handle missing values\n",
        "# For numerical columns, interpolate using spline interpolation\n",
        "numerical_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].interpolate(method='spline', order=3)\n",
        "\n",
        "# Handle any remaining NaNs with forward fill and backward fill\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# For categorical columns, replace NaN with 'Unknown'\n",
        "categorical_columns = ['Weather Type', 'Conditions']\n",
        "merged_data[categorical_columns] = merged_data[categorical_columns].fillna('Unknown')\n",
        "\n",
        "# 2. Handle outliers (example for some key columns)\n",
        "merged_data['Temperature'] = merged_data['Temperature'].clip(lower=-30, upper=45)\n",
        "merged_data['Relative Humidity'] = merged_data['Relative Humidity'].clip(lower=0, upper=100)\n",
        "merged_data['Wind Speed'] = merged_data['Wind Speed'].clip(upper=200)\n",
        "\n",
        "# 3. Create lag features for the target variable (Consumption)\n",
        "# Adding 24-hour lag for Consumption\n",
        "merged_data['Consumption_Lag_24'] = merged_data['Consumption'].shift(24)\n",
        "\n",
        "# Drop rows with NaN introduced by lagging\n",
        "merged_data.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical columns with one-hot encoding\n",
        "merged_data = pd.get_dummies(merged_data, columns=['Weather Type', 'Conditions'], drop_first=True)\n",
        "\n",
        "# 4. Scale numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "scaled_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_data[scaled_columns] = scaler.fit_transform(merged_data[scaled_columns])\n",
        "\n",
        "# Final cleaned and prepared dataset\n",
        "print(merged_data.head())\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = merged_data.drop('Consumption', axis=1)\n",
        "y = merged_data['Consumption']\n",
        "\n",
        "# Reshape data for LSTM\n",
        "import numpy as np\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM: [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "print(f\"Final shape of X: {X.shape}\")\n",
        "print(f\"Final shape of y: {y.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:24:03.125794Z",
          "iopub.execute_input": "2024-11-26T17:24:03.126919Z",
          "iopub.status.idle": "2024-11-26T17:24:05.219423Z",
          "shell.execute_reply.started": "2024-11-26T17:24:03.126863Z",
          "shell.execute_reply": "2024-11-26T17:24:05.217972Z"
        },
        "id": "0-LU-z7KlHzf",
        "outputId": "7b80bb7e-9145-4111-a131-8994195e78ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_30/2702373423.py:20: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  weather_data = weather_data.resample('H').ffill()\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m weather_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResolved Address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Resample weather data to hourly frequency using forward fill\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m weather_data \u001b[38;5;241m=\u001b[39m \u001b[43mweather_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Merge datasets on DateTime\u001b[39;00m\n\u001b[1;32m     23\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(electricity_data, weather_data, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/resample.py:588\u001b[0m, in \u001b[0;36mResampler.ffill\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mffill\u001b[39m(\u001b[38;5;28mself\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m    Forward fill the values.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m    Freq: W-SUN, dtype: float64\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mffill\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/resample.py:1842\u001b[0m, in \u001b[0;36mDatetimeIndexResampler._upsample\u001b[0;34m(self, method, limit, fill_value)\u001b[0m\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masfreq\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1841\u001b[0m         method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1842\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mres_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[1;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5643\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
          ],
          "ename": "ValueError",
          "evalue": "cannot reindex on an axis with duplicate labels",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = weather_data.index.duplicated()\n",
        "print(\"Number of duplicate timestamps:\", duplicates.sum())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:25:28.924791Z",
          "iopub.execute_input": "2024-11-26T17:25:28.9252Z",
          "iopub.status.idle": "2024-11-26T17:25:28.936379Z",
          "shell.execute_reply.started": "2024-11-26T17:25:28.925168Z",
          "shell.execute_reply": "2024-11-26T17:25:28.935125Z"
        },
        "id": "eHLyGKYwlHzg",
        "outputId": "f72f2550-bd64-454b-897d-1d65da8791e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of duplicate timestamps: 160720\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = weather_data.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicate_rows}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:27:05.337913Z",
          "iopub.execute_input": "2024-11-26T17:27:05.338291Z",
          "iopub.status.idle": "2024-11-26T17:27:05.493166Z",
          "shell.execute_reply.started": "2024-11-26T17:27:05.338262Z",
          "shell.execute_reply": "2024-11-26T17:27:05.492074Z"
        },
        "id": "uoPJ07VdlHzg",
        "outputId": "ac77ec64-91d2-40dc-80c4-291849bd4936"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of duplicate rows: 9\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:28:26.356549Z",
          "iopub.execute_input": "2024-11-26T17:28:26.356992Z",
          "iopub.status.idle": "2024-11-26T17:28:26.383292Z",
          "shell.execute_reply.started": "2024-11-26T17:28:26.356957Z",
          "shell.execute_reply": "2024-11-26T17:28:26.381685Z"
        },
        "id": "e_SMZO7BlHzg",
        "outputId": "c6fca198-1ec2-498e-cddf-256adc9201a4"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_30/663698265.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mduplicate_datetime_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicate_datetime_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6946\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6953\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Index(['DateTime'], dtype='object')"
          ],
          "ename": "KeyError",
          "evalue": "Index(['DateTime'], dtype='object')",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:25:41.682721Z",
          "iopub.execute_input": "2024-11-26T17:25:41.683737Z",
          "iopub.status.idle": "2024-11-26T17:25:41.714566Z",
          "shell.execute_reply.started": "2024-11-26T17:25:41.683688Z",
          "shell.execute_reply": "2024-11-26T17:25:41.713378Z"
        },
        "id": "p4yMrWbzlHzh",
        "outputId": "7d12074a-f782-4543-f4f0-04b2a8ecdcd9"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             Date time  Minimum Temperature  Maximum Temperature  Temperature  \\\nDateTime                                                                        \n2011-01-01  01/01/2011                -10.1                 -3.6         -6.9   \n2011-01-02  01/02/2011                 -9.0                 -1.7         -4.6   \n2011-01-03  01/03/2011                 -7.2                 -1.8         -4.0   \n2011-01-04  01/04/2011                 -6.7                 -4.5         -5.7   \n2011-01-05  01/05/2011                -11.5                 -5.0         -7.9   \n\n            Dew Point  Relative Humidity  Heat Index  Wind Speed  Wind Gust  \\\nDateTime                                                                      \n2011-01-01       -8.2              90.62         NaN         8.9       21.6   \n2011-01-02       -6.0              89.80         NaN         8.8       14.4   \n2011-01-03       -5.0              93.01         NaN         8.7        7.2   \n2011-01-04       -7.4              87.73         NaN         7.0       14.4   \n2011-01-05      -10.2              83.54         NaN         8.0       15.1   \n\n            Wind Direction  Wind Chill  Precipitation  Precipitation Cover  \\\nDateTime                                                                     \n2011-01-01          247.43        -8.2            0.0                  0.0   \n2011-01-02          229.96       -11.8            0.0                  0.0   \n2011-01-03          241.96        -9.4            0.0                  0.0   \n2011-01-04          221.46        -9.6            0.0                  0.0   \n2011-01-05          116.25       -15.1            0.0                  0.0   \n\n            Snow Depth  Visibility  Cloud Cover  Sea Level Pressure  \\\nDateTime                                                              \n2011-01-01        3.32         4.8         71.6              1022.3   \n2011-01-02        2.76         6.5         74.1              1017.9   \n2011-01-03        3.12         4.3         94.5              1021.1   \n2011-01-04        3.12         7.4         96.6              1026.5   \n2011-01-05        3.12         8.1         61.1              1027.9   \n\n                                               Weather Type        Conditions  \nDateTime                                                                       \n2011-01-01                                             Mist  Partially cloudy  \n2011-01-02                            Mist, Light Snow, Fog  Partially cloudy  \n2011-01-03                      Mist, Light Snow, Fog, Snow          Overcast  \n2011-01-04  Mist, Light Snow, Sky Coverage Increasing, Snow          Overcast  \n2011-01-05                                             Mist  Partially cloudy  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date time</th>\n      <th>Minimum Temperature</th>\n      <th>Maximum Temperature</th>\n      <th>Temperature</th>\n      <th>Dew Point</th>\n      <th>Relative Humidity</th>\n      <th>Heat Index</th>\n      <th>Wind Speed</th>\n      <th>Wind Gust</th>\n      <th>Wind Direction</th>\n      <th>Wind Chill</th>\n      <th>Precipitation</th>\n      <th>Precipitation Cover</th>\n      <th>Snow Depth</th>\n      <th>Visibility</th>\n      <th>Cloud Cover</th>\n      <th>Sea Level Pressure</th>\n      <th>Weather Type</th>\n      <th>Conditions</th>\n    </tr>\n    <tr>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2011-01-01</th>\n      <td>01/01/2011</td>\n      <td>-10.1</td>\n      <td>-3.6</td>\n      <td>-6.9</td>\n      <td>-8.2</td>\n      <td>90.62</td>\n      <td>NaN</td>\n      <td>8.9</td>\n      <td>21.6</td>\n      <td>247.43</td>\n      <td>-8.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.32</td>\n      <td>4.8</td>\n      <td>71.6</td>\n      <td>1022.3</td>\n      <td>Mist</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2011-01-02</th>\n      <td>01/02/2011</td>\n      <td>-9.0</td>\n      <td>-1.7</td>\n      <td>-4.6</td>\n      <td>-6.0</td>\n      <td>89.80</td>\n      <td>NaN</td>\n      <td>8.8</td>\n      <td>14.4</td>\n      <td>229.96</td>\n      <td>-11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.76</td>\n      <td>6.5</td>\n      <td>74.1</td>\n      <td>1017.9</td>\n      <td>Mist, Light Snow, Fog</td>\n      <td>Partially cloudy</td>\n    </tr>\n    <tr>\n      <th>2011-01-03</th>\n      <td>01/03/2011</td>\n      <td>-7.2</td>\n      <td>-1.8</td>\n      <td>-4.0</td>\n      <td>-5.0</td>\n      <td>93.01</td>\n      <td>NaN</td>\n      <td>8.7</td>\n      <td>7.2</td>\n      <td>241.96</td>\n      <td>-9.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.12</td>\n      <td>4.3</td>\n      <td>94.5</td>\n      <td>1021.1</td>\n      <td>Mist, Light Snow, Fog, Snow</td>\n      <td>Overcast</td>\n    </tr>\n    <tr>\n      <th>2011-01-04</th>\n      <td>01/04/2011</td>\n      <td>-6.7</td>\n      <td>-4.5</td>\n      <td>-5.7</td>\n      <td>-7.4</td>\n      <td>87.73</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>14.4</td>\n      <td>221.46</td>\n      <td>-9.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.12</td>\n      <td>7.4</td>\n      <td>96.6</td>\n      <td>1026.5</td>\n      <td>Mist, Light Snow, Sky Coverage Increasing, Snow</td>\n      <td>Overcast</td>\n    </tr>\n    <tr>\n      <th>2011-01-05</th>\n      <td>01/05/2011</td>\n      <td>-11.5</td>\n      <td>-5.0</td>\n      <td>-7.9</td>\n      <td>-10.2</td>\n      <td>83.54</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>15.1</td>\n      <td>116.25</td>\n      <td>-15.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.12</td>\n      <td>8.1</td>\n      <td>61.1</td>\n      <td>1027.9</td>\n      <td>Mist</td>\n      <td>Partially cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "### Merging the electicity dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "YCceRRvAlHzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### converting the hourly electricity dataset to daily and merging with weather data"
      ],
      "metadata": {
        "id": "LZvnotXjlHzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load datasets\n",
        "electricity_data = pd.read_csv('/kaggle/input/hourly-electricity-consumption-and-production/electricityConsumptionAndProductioction.csv')\n",
        "weather_data = pd.read_csv('/kaggle/input/romania-weather-visual-crossing-weather/weather_2011-2021_Romania.csv', encoding='latin1')\n",
        "\n",
        "# Convert datetime columns to pandas datetime format\n",
        "electricity_data['DateTime'] = pd.to_datetime(electricity_data['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
        "weather_data['DateTime'] = pd.to_datetime(weather_data['Date time'], format='%m/%d/%Y')\n",
        "\n",
        "# Set DateTime as the index for both datasets\n",
        "electricity_data.set_index('DateTime', inplace=True)\n",
        "weather_data.set_index('DateTime', inplace=True)\n",
        "\n",
        "# Drop unnecessary columns from the weather dataset\n",
        "weather_data.drop(['Address', 'Name', 'Info', 'Resolved Address', 'Latitude', 'Longitude'], axis=1, inplace=True)\n",
        "\n",
        "# Resample electricity data to daily frequency (using sum for production and consumption)\n",
        "electricity_data_daily = electricity_data.resample('D').agg({\n",
        "    'Consumption': 'sum',         # Sum of consumption per day\n",
        "    'Production': 'sum',          # Sum of total production per day\n",
        "    'Nuclear': 'sum',             # Sum of nuclear production per day\n",
        "    'Wind': 'sum',                # Sum of wind production per day\n",
        "    'Hydroelectric': 'sum',       # Sum of hydroelectric production per day\n",
        "    'Oil and Gas': 'sum',         # Sum of oil and gas production per day\n",
        "    'Coal': 'sum',                # Sum of coal production per day\n",
        "    'Solar': 'sum',               # Sum of solar production per day\n",
        "    'Biomass': 'sum'              # Sum of biomass production per day\n",
        "})\n",
        "\n",
        "# Merge the daily electricity data with the weather data (weather data is already daily)\n",
        "merged_data = pd.merge(electricity_data_daily, weather_data, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "# 1. Handle missing values using spline interpolation\n",
        "numerical_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Applying spline interpolation on the numerical columns (order=3 for cubic spline)\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].interpolate(method='spline', order=3)\n",
        "\n",
        "# Handle any remaining NaNs with forward fill and backward fill if spline doesn't cover all\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# For categorical columns, replace NaN with 'Unknown'\n",
        "categorical_columns = ['Weather Type', 'Conditions']\n",
        "merged_data[categorical_columns] = merged_data[categorical_columns].fillna('Unknown')\n",
        "\n",
        "# 2. Handle outliers (example for some key columns)\n",
        "merged_data['Temperature'] = merged_data['Temperature'].clip(lower=-30, upper=45)\n",
        "merged_data['Relative Humidity'] = merged_data['Relative Humidity'].clip(lower=0, upper=100)\n",
        "merged_data['Wind Speed'] = merged_data['Wind Speed'].clip(upper=200)\n",
        "\n",
        "# 3. Create lag features for the target variable (Consumption)\n",
        "# Adding 24-hour lag for Consumption\n",
        "merged_data['Consumption_Lag_24'] = merged_data['Consumption'].shift(24)\n",
        "\n",
        "# Drop rows with NaN introduced by lagging\n",
        "merged_data.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical columns with one-hot encoding\n",
        "merged_data = pd.get_dummies(merged_data, columns=['Weather Type', 'Conditions'], drop_first=True)\n",
        "\n",
        "# 4. Scale numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "scaled_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_data[scaled_columns] = scaler.fit_transform(merged_data[scaled_columns])\n",
        "\n",
        "# Final cleaned and prepared dataset\n",
        "print(merged_data.head())\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = merged_data.drop('Consumption', axis=1)\n",
        "y = merged_data['Consumption']\n",
        "\n",
        "# Reshape data for LSTM\n",
        "import numpy as np\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM: [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "print(f\"Final shape of X: {X.shape}\")\n",
        "print(f\"Final shape of y: {y.shape}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T17:35:40.570165Z",
          "iopub.execute_input": "2024-11-26T17:35:40.570933Z",
          "iopub.status.idle": "2024-11-26T17:36:14.188086Z",
          "shell.execute_reply.started": "2024-11-26T17:35:40.570896Z",
          "shell.execute_reply": "2024-11-26T17:36:14.187023Z"
        },
        "id": "DNRN7hDWlHzi",
        "outputId": "cac356bf-d357-441f-84f7-efd7f67d3ecf"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_30/3014716691.py:42: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  merged_data[numerical_columns] = merged_data[numerical_columns].fillna(method='ffill').fillna(method='bfill')\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "            Consumption  Production   Nuclear      Wind  Hydroelectric  \\\nDateTime                                                                 \n2019-01-01     0.338431    0.391314  0.833035  0.128612       0.200952   \n2019-01-01     0.338431    0.391314  0.833035  0.128612       0.200952   \n2019-01-01     0.338431    0.391314  0.833035  0.128612       0.200952   \n2019-01-01     0.338431    0.391314  0.833035  0.128612       0.200952   \n2019-01-01     0.338431    0.391314  0.833035  0.128612       0.200952   \n\n            Oil and Gas      Coal     Solar   Biomass   Date time  ...  \\\nDateTime                                                           ...   \n2019-01-01     0.649517  0.543092  0.091929  0.177276  01/01/2019  ...   \n2019-01-01     0.649517  0.543092  0.091929  0.177276  01/01/2019  ...   \n2019-01-01     0.649517  0.543092  0.091929  0.177276  01/01/2019  ...   \n2019-01-01     0.649517  0.543092  0.091929  0.177276  01/01/2019  ...   \n2019-01-01     0.649517  0.543092  0.091929  0.177276  01/01/2019  ...   \n\n            Weather Type_Thunderstorm, Thunderstorm Without Precipitation, Sky Coverage Increasing  \\\nDateTime                                                                                             \n2019-01-01                                              False                                        \n2019-01-01                                              False                                        \n2019-01-01                                              False                                        \n2019-01-01                                              False                                        \n2019-01-01                                              False                                        \n\n            Weather Type_Thunderstorm, Thunderstorm Without Precipitation, Sky Coverage Increasing, Sky Unchanged  \\\nDateTime                                                                                                            \n2019-01-01                                              False                                                       \n2019-01-01                                              False                                                       \n2019-01-01                                              False                                                       \n2019-01-01                                              False                                                       \n2019-01-01                                              False                                                       \n\n            Weather Type_Thunderstorm, Thunderstorm Without Precipitation, Sky Unchanged  \\\nDateTime                                                                                   \n2019-01-01                                              False                              \n2019-01-01                                              False                              \n2019-01-01                                              False                              \n2019-01-01                                              False                              \n2019-01-01                                              False                              \n\n            Weather Type_Unknown  Conditions_Overcast  \\\nDateTime                                                \n2019-01-01                 False                False   \n2019-01-01                 False                False   \n2019-01-01                 False                False   \n2019-01-01                 False                False   \n2019-01-01                 False                False   \n\n            Conditions_Partially cloudy  Conditions_Rain  \\\nDateTime                                                   \n2019-01-01                        False            False   \n2019-01-01                        False            False   \n2019-01-01                        False            False   \n2019-01-01                        False             True   \n2019-01-01                         True            False   \n\n            Conditions_Rain, Overcast  Conditions_Rain, Partially cloudy  \\\nDateTime                                                                   \n2019-01-01                      False                               True   \n2019-01-01                       True                              False   \n2019-01-01                      False                               True   \n2019-01-01                      False                              False   \n2019-01-01                      False                              False   \n\n            Conditions_Unknown  \nDateTime                        \n2019-01-01               False  \n2019-01-01               False  \n2019-01-01               False  \n2019-01-01               False  \n2019-01-01               False  \n\n[5 rows x 5511 columns]\nFinal shape of X: (44912, 1, 5510)\nFinal shape of y: (44912,)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now converting the daily weather data into hourly data using interpolation method."
      ],
      "metadata": {
        "id": "P2U4eTNHlHzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load datasets\n",
        "electricity_data = pd.read_csv('/kaggle/input/hourly-electricity-consumption-and-production/electricityConsumptionAndProductioction.csv')\n",
        "weather_data = pd.read_csv('/kaggle/input/romania-weather-visual-crossing-weather/weather_2011-2021_Romania.csv', encoding='latin1')\n",
        "\n",
        "# Convert datetime columns to pandas datetime format\n",
        "electricity_data['DateTime'] = pd.to_datetime(electricity_data['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
        "weather_data['DateTime'] = pd.to_datetime(weather_data['Date time'], format='%m/%d/%Y')\n",
        "\n",
        "# Set DateTime as the index for both datasets\n",
        "electricity_data.set_index('DateTime', inplace=True)\n",
        "weather_data.set_index('DateTime', inplace=True)\n",
        "\n",
        "# Drop unnecessary columns from the weather dataset\n",
        "weather_data.drop(['Address', 'Name', 'Info', 'Resolved Address', 'Latitude', 'Longitude'], axis=1, inplace=True)\n",
        "\n",
        "# Resample electricity data to daily frequency (using sum for production and consumption)\n",
        "electricity_data_daily = electricity_data.resample('D').agg({\n",
        "    'Consumption': 'sum',         # Sum of consumption per day\n",
        "    'Production': 'sum',          # Sum of total production per day\n",
        "    'Nuclear': 'sum',             # Sum of nuclear production per day\n",
        "    'Wind': 'sum',                # Sum of wind production per day\n",
        "    'Hydroelectric': 'sum',       # Sum of hydroelectric production per day\n",
        "    'Oil and Gas': 'sum',         # Sum of oil and gas production per day\n",
        "    'Coal': 'sum',                # Sum of coal production per day\n",
        "    'Solar': 'sum',               # Sum of solar production per day\n",
        "    'Biomass': 'sum'              # Sum of biomass production per day\n",
        "})\n",
        "\n",
        "# Resample the weather data to hourly frequency using forward fill\n",
        "# Resampling to hourly data by forward filling the missing data\n",
        "weather_data_resampled = weather_data.resample('H').ffill()\n",
        "\n",
        "# Apply spline interpolation to the resampled weather data for filling missing values\n",
        "numerical_columns_weather = weather_data_resampled.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Apply spline interpolation on weather data's numerical columns (order=3 for cubic spline)\n",
        "weather_data_resampled[numerical_columns_weather] = weather_data_resampled[numerical_columns_weather].interpolate(method='spline', order=3)\n",
        "\n",
        "# Handle any remaining NaNs with forward fill and backward fill if spline doesn't cover all\n",
        "weather_data_resampled[numerical_columns_weather] = weather_data_resampled[numerical_columns_weather].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Now merge the daily electricity data with the resampled weather data (they are now aligned)\n",
        "merged_data = pd.merge(electricity_data_daily, weather_data_resampled, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "# Handle missing values for merged dataset using spline interpolation\n",
        "numerical_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].interpolate(method='spline', order=3)\n",
        "\n",
        "# Handle any remaining NaNs with forward fill and backward fill if spline doesn't cover all\n",
        "merged_data[numerical_columns] = merged_data[numerical_columns].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# For categorical columns, replace NaN with 'Unknown'\n",
        "categorical_columns = ['Weather Type', 'Conditions']\n",
        "merged_data[categorical_columns] = merged_data[categorical_columns].fillna('Unknown')\n",
        "\n",
        "# Handle outliers (example for some key columns)\n",
        "merged_data['Temperature'] = merged_data['Temperature'].clip(lower=-30, upper=45)\n",
        "merged_data['Relative Humidity'] = merged_data['Relative Humidity'].clip(lower=0, upper=100)\n",
        "merged_data['Wind Speed'] = merged_data['Wind Speed'].clip(upper=200)\n",
        "\n",
        "# Create lag features for the target variable (Consumption)\n",
        "# Adding 24-hour lag for Consumption\n",
        "merged_data['Consumption_Lag_24'] = merged_data['Consumption'].shift(24)\n",
        "\n",
        "# Drop rows with NaN introduced by lagging\n",
        "merged_data.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical columns with one-hot encoding\n",
        "merged_data = pd.get_dummies(merged_data, columns=['Weather Type', 'Conditions'], drop_first=True)\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "scaled_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_data[scaled_columns] = scaler.fit_transform(merged_data[scaled_columns])\n",
        "\n",
        "# Final cleaned and prepared dataset\n",
        "print(merged_data.head())\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = merged_data.drop('Consumption', axis=1)\n",
        "y = merged_data['Consumption']\n",
        "\n",
        "# Reshape data for LSTM\n",
        "import numpy as np\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM: [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "print(f\"Final shape of X: {X.shape}\")\n",
        "print(f\"Final shape of y: {y.shape}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "dj50ChIvlHzj"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}